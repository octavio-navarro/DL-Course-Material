{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "3. DL. Keras Introduction.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVCR_J6F6Tvs"
      },
      "source": [
        "# Deep learning steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7nflKCE6Tvv"
      },
      "source": [
        "#### Gather the dataset\n",
        "\n",
        "The first component of building a deep learning network is to gather our initial dataset. We need the data itself as well as the labels associated with each data point. These labels should come from a finite set of categories, such as: categories = dog, cat, panda.\n",
        "\n",
        "#### Split Your Dataset \n",
        "\n",
        "Now that we have our initial dataset, we need to split it into two parts: 1. A training set 2. A testing set A training set is used by our classifier to “learn” what each category looks like by making predictions on the input data and then correct itself when predictions are wrong. After the classifier has been trained, we can evaluate the performing on a testing set. Here are some common data splits:\n",
        "\n",
        "![data splits](https://github.com/octavio-navarro/DL-Course-Material/blob/master/Notebooks/images/test_train_split.png?raw=1)\n",
        "\n",
        "You should create a third data split called the validation set. This set of the data (normally) comes from the training data and is used as “fake test data” to tune the hyperparameters. Only after have we determined the hyperparameter values using the validation set do we move on to collecting final accuracy results in the testing data. We normally allocate roughly 10-20% of the training data for validation.\n",
        "\n",
        "#### Train the network\n",
        "\n",
        "Given our training set of images, we can now train our network. The goal here is for our network to learn how to recognize each of the categories in our labeled data. When the model makes a mistake, it learns from this mistake and improves itself.\n",
        "\n",
        "#### Evaluate\n",
        "\n",
        "Last, we need to evaluate our trained network. For each of the data in our testing set, we present them to the network and ask it to predict what it thinks the label of the data is. These model predictions are compared to the ground-truth labels from our testing set. The ground-truth labels represent what the data category actually is. From there, we can compute the number of predictions our classifier got correct and compute aggregate reports such as precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NUTBggq6Tvw"
      },
      "source": [
        "# Keras\n",
        "\n",
        "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\n",
        "\n",
        "Keras allows:\n",
        "\n",
        "1. Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
        "2. Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
        "3. Runs seamlessly on CPU and GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc6_6lVm6Tvx"
      },
      "source": [
        "# Mnist with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0jQFA_M6Tvx"
      },
      "source": [
        "#### Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYLA9Mg96Tvx",
        "outputId": "089e81fc-98f6-402b-bf72-07518b8f00fc"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"Tensforflow version:{tf.__version__}\")\n",
        "print(f\"Keras version:{tf.keras.__version__}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensforflow version:2.5.0\n",
            "Keras version:2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rFtlZws6Tvy"
      },
      "source": [
        "#### Load and standardize the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn4KkplZ6Tvz",
        "outputId": "3a729415-3912-46b1-f6fe-21a11f647d1e"
      },
      "source": [
        "# load the data, and separate it into train and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Standardize the data\n",
        "\n",
        "# flatten arrays\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "\n",
        "# turn values from 0-255 to 0-1\n",
        "train_images = train_images.astype('float32') / 255 \n",
        "\n",
        "# same starndadization for the test images\n",
        "test_images = test_images.reshape((10000, 28 * 28)) \n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# one hot encoding\n",
        "train_labels = to_categorical(train_labels) \n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGr2fmIh6Tvz"
      },
      "source": [
        "#### Create and compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf2HwoJe6Tv0",
        "outputId": "f7f7505c-7136-464f-f173-71e9f7f52d71"
      },
      "source": [
        "# The keras.models.Sequential class is a wrapper for the neural network model that treats \n",
        "# the network as a sequence of layers\n",
        "network = models.Sequential()\n",
        "\n",
        "# Dense layers: fully connected layers\n",
        "network.add(layers.Dense(64, activation='sigmoid', input_shape=(28 * 28,))) \n",
        "network.add(layers.Dense(32, activation='sigmoid'))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Once we have our model built, we need to compile it before it can be run. \n",
        "#Compiling the Keras model calls the backend (tensorflow, theano, etc.) and binds the optimizer, \n",
        "#loss function, and other parameters required before the model can be run on any input data.\n",
        "\n",
        "# loss function: basically, the error function. categorical crossentropy is one of many.\n",
        "\n",
        "# optimizer: this is the mechanism through which the network will update itself.\n",
        "# Stochastic Gradient descent (sgd) is one of those.\n",
        "\n",
        "# Metrics to monitor during training and testing. Here we will only care about accuracy.\n",
        "network.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "network.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 52,650\n",
            "Trainable params: 52,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WXt98Za6Tv0"
      },
      "source": [
        "#### Train the model\n",
        "\n",
        "The model is trained with the fit() method, through the following command that specifies the number of training epochs and the message level (how much information we want displayed on the screen during training)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPXWo-wu6Tv1",
        "outputId": "eec41285-ca1a-44c4-a639-6d507a0a22a4"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=50)\n",
        "\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"test loss: \", test_loss, \"test accuracy: \", test_acc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.1933 - accuracy: 0.3641\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.7529 - accuracy: 0.5663\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.2650 - accuracy: 0.6906\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.9379 - accuracy: 0.7767\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7359 - accuracy: 0.8254\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6125 - accuracy: 0.8485\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5348 - accuracy: 0.8637\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4828 - accuracy: 0.8731\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4455 - accuracy: 0.8819\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4174 - accuracy: 0.8874\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3950 - accuracy: 0.8917\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3769 - accuracy: 0.8963\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3618 - accuracy: 0.8994\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3489 - accuracy: 0.9021\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3376 - accuracy: 0.9053\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3276 - accuracy: 0.9074\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3186 - accuracy: 0.9092\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3105 - accuracy: 0.9117\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3029 - accuracy: 0.9137\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2959 - accuracy: 0.9156\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2894 - accuracy: 0.9173\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2833 - accuracy: 0.9192\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2776 - accuracy: 0.9203\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2720 - accuracy: 0.9219\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2667 - accuracy: 0.9237\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2617 - accuracy: 0.9251\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2568 - accuracy: 0.9263\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2522 - accuracy: 0.9279\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2477 - accuracy: 0.9294\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2434 - accuracy: 0.9303\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2391 - accuracy: 0.9316\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2350 - accuracy: 0.9327\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2312 - accuracy: 0.9341\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2274 - accuracy: 0.9352\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2236 - accuracy: 0.9363\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2200 - accuracy: 0.9371\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2165 - accuracy: 0.9376\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2131 - accuracy: 0.9389\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2098 - accuracy: 0.9402\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2066 - accuracy: 0.9410\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2036 - accuracy: 0.9414\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2005 - accuracy: 0.9421\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1975 - accuracy: 0.9432\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1947 - accuracy: 0.9439\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1919 - accuracy: 0.9446\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1892 - accuracy: 0.9456\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1865 - accuracy: 0.9463\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1839 - accuracy: 0.9471\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1813 - accuracy: 0.9477\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1788 - accuracy: 0.9484\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1808 - accuracy: 0.9471\n",
            "test loss:  0.18083950877189636 test accuracy:  0.9470999836921692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "rLZ5bNAd6Tv1",
        "outputId": "1562ffbb-f00f-4252-b86a-c98232f47f24"
      },
      "source": [
        "# make a prediction on a specific image from the test data\n",
        "test_index = 8\n",
        "\n",
        "input_image = test_images[test_index].reshape(28*28)\n",
        "prediction = network.predict(np.array([input_image]))\n",
        "\n",
        "np.set_printoptions(precision=3, suppress= True)\n",
        "print(prediction, test_labels[test_index])\n",
        "\n",
        "plt.title(\"Label: \" + str(test_labels[test_index]))\n",
        "plt.imshow(test_images[test_index].reshape(28,28), cmap=\"gray\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.005 0.    0.004 0.    0.037 0.02  0.931 0.    0.003 0.001]] [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faaf5cf7410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}